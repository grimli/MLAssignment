---
title: "Machine Learning Course Project"
author: "Edoardo Bompiani"
date: "04 luglio 2017"
output: html_document
---

```{r setup, include=FALSE}
library(knitr)
knitr::opts_chunk$set(echo = TRUE)
```

## Executive Summary 
The goal of this project is to analyze the data in the WLE dataset to produce a model that predict the **class** variable from a subset of the other fields describing how the model was built, how cross validation was used, what is  the expected out of sample error, the reasons for the choices done. The prediction model will be used to predict the 20 different test cases too.

The class variable describes the exercise execution: **A** indicating a correct execution and the other classes indicating 4 different common errors in wheight lift. A more detailed description of the dataset can be get here http://groupware.les.inf.puc-rio.br/har. 

The **W**eight **L**ifting **E**xercises (WLE) Dataset is is licensed under the Creative Commons license (CC BY-SA) and gently made availabel by Velloso, E.; Bulling, A.; Gellersen, H.; Ugulino, W.; Fuks, H. as support to the article.

*Velloso, E.; Bulling, A.; Gellersen, H.; Ugulino, W.; Fuks, H. Qualitative Activity Recognition of Weight Lifting Exercises. Proceedings of 4th International Conference in Cooperation with SIGCHI (Augmented Human '13) . Stuttgart, Germany: ACM SIGCHI, 2013.*

## Preprocessing
The **caret** library is loaded to be used in the analysis and the working directory is set to the directory containing the downloaded data

```{r}
library(caret)
library(dplyr)
```

The dataset is loaded from two files and copied into two variables
```{r}
destfile_test <- "./pml-testing.csv"
destfile_train <- "./pml-training.csv"

if(!file.exists(destfile_test)){
    res <- tryCatch(download.file("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv",
                              destfile="./data/pml-testing.csv",
                              method="auto"),
                error=function(e) 1)
}

if(!file.exists(destfile_train)){
    res <- tryCatch(download.file("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv",
                              destfile="./data/pml-training.csv",
                              method="auto"),
                error=function(e) 1)
}

dfTrain <- read.csv(destfile_train)
dfTest <- read.csv(destfile_test)
``` 

Several preprocessing activity are required to avoid problem with this dataset.
To avoid problems with the sampling we'll not consider variables with near to zero variance. To accomplish this the caret package provide the nearZeroVar() function.
 
```{r}
dfTrain <- dfTrain <- dfTrain[,-nearZeroVar(dfTrain)]
```

Incomplete variables are not considered too
```{r}
dfTrain <- dfTrain[, complete.cases(t(dfTrain))]
```

Some variables are tags, used to identify the subject or the measure and should not be used to determinate the classe
```{r}
dfTrain <- dfTrain[, -grep("X", names(dfTrain))]
dfTrain <- dfTrain[, -grep("user_name", names(dfTrain))]
```

Some variables are used to determinate the temporal sequence in the exercises. These variables would reflect the order in the exercise execution and would determinate the class just because the exercises are executed in a specific order. These variables are then excluded too  
```{r}
dfTrain <- dfTrain[, -grep("timestamp", names(dfTrain))]
```

A partition in the training set is created to have a subset to use in the cross validation step:
```{r}
set.seed(2740)
inTrain <- createDataPartition(y=dfTrain$classe, p=.7, list=FALSE)
dfTrainT <- dfTrain[inTrain, ]
dfTrainV <- dfTrain[-inTrain, ]
```

The same subset of variables is selected in the test data too
```{r}
variables <- names(dfTrain)
dfTest <- dfTest[,names(dfTest) %in% variables]
```

## Analysis
Several predicion models are available. Some have been picked up considering the execution time too. 
The resulting prediction are used to build combined model too.

### Random Tree
We start with Random Tree, a simple method
```{r, cache=TRUE}
set.seed(1332)
fitRT <- train( classe ~ ., data = dfTrainT, method = "rpart", maxdepth=20)
predRT <- predict( fitRT, newdata = dfTrainV )
cmRT <- confusionMatrix(predRT, dfTrainV$classe)
cmRT
```
The results of this method, with the D Class completly undiscovered and an accuracy of 0.59, are not particularly interesting.

## Boosting
```{r, cache=TRUE}
fitBT <- train( classe ~ ., data = dfTrainT, method = "gbm", verbose = FALSE)
predBT <- predict( fitBT, newdata = dfTrainV )
cmBT <- confusionMatrix(predBT, dfTrainV$classe)
cmBT
```
The Boosting method is more sofisticated and computationally requiring but gives much better results. This time we have got an accuracy of 0.985.

## Linear Discriminant analysis
As final model we consider the Linear Discriminant analysis
```{r, cache=TRUE}
fitLDA <- train( classe ~ ., data = dfTrainT, method = "lda")
predLDA <- predict( fitLDA, newdata = dfTrainV )
cmLDA <- confusionMatrix(predLDA, dfTrainV$classe)
cmLDA
```
The accuracy of this model is not as good as with the boosting method but not as bet as for the Random Tree method.

### Combined prediction
In this last analysis step we try to get a more accurate solution combining the previous results with the random forest method
```{r, cache=TRUE}
predDF <- data.frame(predBT, predLDA, predRT, classe=dfTrainV$classe)
fitComb <- train(classe ~ . , data = predDF, method="rf")
predComb <- predict(fitComb, dfTrainV)
cmComb <- confusionMatrix(predComb, dfTrainV$classe)
cmComb
```

### Model Comparison
The Accuracy of the four models can be compared
```{r, cache=TRUE}
rbind( c("Random Tree", cmRT$overall[1]),
    c("Boosted", cmBT$overall[1]),
    c("Linear Discriminant", cmLDA$overall[1]),
    c("Combined", cmComb$overall[1]))
```
The boosted shows better results and no real advantage is got combining this method with the other.

## Test dataset analysis 
We can now apply the chosen model to the test dataset
```{r, cache=TRUE}
predTest <- predict(fitBT, dfTest )
predTest
```